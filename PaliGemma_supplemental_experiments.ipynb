{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPldk8n0tN2eAFi+O2ch/Q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravsels/paligemma_from_scratch/blob/main/PaliGemma_supplemental_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20vAShNH1T79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c69439-4090-47e7-ea6c-0c610657ef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "6FW1ysvv8Div",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "4a04a988-aba5-4851-8f41-e570194dd723"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchviz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e238e6edc9d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchviz'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SuperSimpleModel(nn.Module):\n",
        "   class_tensor = torch.tensor([4, 5, 6])  # Class attribute\n",
        "\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.instance_tensor = torch.tensor([7, 8, 9])  # Instance attribute\n",
        "        self.register_buffer('buffer_tensor', torch.tensor([10, 11, 12]))\n",
        "\n",
        "        self.default_param = nn.Parameter(torch.randn(3))\n",
        "\n",
        "   def forward(self, x):\n",
        "        inline_tensor = torch.tensor([13, 14, 15])\n",
        "\n",
        "        result = x + self.class_tensor * 2 +  \\\n",
        "            self.instance_tensor * 2 +    \\\n",
        "            self.buffer_tensor * 2 +    \\\n",
        "            inline_tensor * 2 + self.default_param\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "JjlSIZfk6mvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "\n",
        "model = SuperSimpleModel()\n",
        "\n",
        "y = model(x)"
      ],
      "metadata": {
        "id": "s01Fphnc1yjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyd7xF-p14dT",
        "outputId": "a25c354b-0b35-490b-e793-66e2b51334a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('default_param', tensor([0.2109, 0.0087, 0.2786])),\n",
              "             ('buffer_tensor', tensor([10, 11, 12]))])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "\n",
        "print('listing params : ')\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pQVnW-w1-gv",
        "outputId": "84af57f9-b12e-4251-b47f-9312a00fddfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 3\n",
            "listing params : \n",
            "default_param torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(y, params=dict(model.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "_UE9ca6L8Nkg",
        "outputId": "0ac2ce52-7acc-43ca-f691-9b56fae830c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"215pt\"\n viewBox=\"0.00 0.00 109.00 215.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-211 105,-211 105,4 -4,4\"/>\n<!-- 132419430539312 -->\n<g id=\"node1\" class=\"node\">\n<title>132419430539312</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 132419430215984 -->\n<g id=\"node2\" class=\"node\">\n<title>132419430215984</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 132419430215984&#45;&gt;132419430539312 -->\n<g id=\"edge3\" class=\"edge\">\n<title>132419430215984&#45;&gt;132419430539312</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 132419430210848 -->\n<g id=\"node3\" class=\"node\">\n<title>132419430210848</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132419430210848&#45;&gt;132419430215984 -->\n<g id=\"edge1\" class=\"edge\">\n<title>132419430210848&#45;&gt;132419430215984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 132419430179056 -->\n<g id=\"node4\" class=\"node\">\n<title>132419430179056</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"98,-207 3,-207 3,-177 98,-177 98,-207\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">default_param</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 132419430179056&#45;&gt;132419430210848 -->\n<g id=\"edge2\" class=\"edge\">\n<title>132419430179056&#45;&gt;132419430210848</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.84C50.5,-169.21 50.5,-159.7 50.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.27 50.5,-141.27 47,-151.27 54,-151.27\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x786f4d0ae390>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "   class_tensor = torch.tensor([4, 5, 6])  # Class attribute\n",
        "\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.instance_tensor = torch.tensor([7, 8, 9])  # Instance attribute\n",
        "        self.register_buffer('buffer_tensor', torch.tensor([10, 11, 12]))\n",
        "\n",
        "        self.default_param = nn.Parameter(torch.randn(3))\n",
        "\n",
        "        # Added layers\n",
        "        self.conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
        "        self.linear = nn.Linear(16, 3)  # Output size 3 to match other tensors\n",
        "\n",
        "   def forward(self, x):\n",
        "        inline_tensor = torch.tensor([13, 14, 15])\n",
        "\n",
        "        # Process through conv and linear\n",
        "        x = self.conv(x)  # Expects x shape: [batch, 3, H, W]\n",
        "        x = x.mean(dim=[2,3])  # Global average pooling to reduce spatial dims\n",
        "        x = self.linear(x)  # To match size of other tensors\n",
        "\n",
        "        result = x + self.class_tensor * 2 +  \\\n",
        "            self.instance_tensor * 2 +    \\\n",
        "            self.buffer_tensor * 2 +    \\\n",
        "            inline_tensor * 2 + self.default_param\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "w6kvSlWT40Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 32, 32)  # [batch=1, channels=3, height=32, width=32]\n",
        "x = x.float()\n",
        "\n",
        "model = SimpleModel()\n",
        "\n",
        "y = model.forward(x)"
      ],
      "metadata": {
        "id": "D6Xl7mEN6umj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfLKGt9D60k-",
        "outputId": "bb0c2cf7-f282-4c1b-cb33-c71f977a82fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('default_param', tensor([ 0.8787, -0.8073,  0.6710])),\n",
              "             ('buffer_tensor', tensor([10, 11, 12])),\n",
              "             ('conv.weight',\n",
              "              tensor([[[[-1.2175e-01,  1.8980e-01, -1.3006e-01],\n",
              "                        [ 9.1079e-02,  7.3207e-02,  1.4001e-01],\n",
              "                        [ 8.6133e-02, -6.9317e-03,  1.5753e-01]],\n",
              "              \n",
              "                       [[-1.8307e-01,  1.7288e-02,  1.0325e-01],\n",
              "                        [ 1.0669e-02,  1.1352e-01, -2.5215e-02],\n",
              "                        [-5.1842e-02, -1.6308e-02,  9.2067e-03]],\n",
              "              \n",
              "                       [[-1.7288e-01,  7.0757e-02,  6.2713e-02],\n",
              "                        [ 5.7581e-02, -1.2314e-01, -3.6668e-02],\n",
              "                        [-9.9316e-02,  1.3665e-01, -4.5963e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.7256e-01, -1.6920e-01, -1.7107e-01],\n",
              "                        [-1.0477e-01,  2.6244e-02, -1.0988e-01],\n",
              "                        [ 8.2875e-02, -1.7794e-01,  1.8268e-01]],\n",
              "              \n",
              "                       [[-1.3815e-01, -1.4626e-01, -4.2695e-02],\n",
              "                        [ 1.8738e-01,  8.3941e-02,  5.1944e-02],\n",
              "                        [ 6.8821e-02,  1.4719e-01, -7.3634e-02]],\n",
              "              \n",
              "                       [[ 2.2964e-02,  6.9699e-02,  1.7836e-01],\n",
              "                        [-9.4939e-02,  5.3039e-02,  3.7018e-02],\n",
              "                        [-1.4108e-01,  6.8835e-02,  1.9200e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.0491e-02,  6.1725e-02, -1.0046e-01],\n",
              "                        [ 1.5958e-01, -1.2301e-04,  1.6646e-01],\n",
              "                        [ 1.8112e-01,  1.1690e-01, -1.5815e-01]],\n",
              "              \n",
              "                       [[ 1.1147e-01, -9.0244e-02, -5.2607e-02],\n",
              "                        [ 9.6587e-02,  7.3908e-02, -8.7764e-02],\n",
              "                        [-1.9160e-01, -5.9093e-02, -1.2358e-01]],\n",
              "              \n",
              "                       [[ 1.1788e-02,  3.0141e-02,  4.4769e-02],\n",
              "                        [-8.0854e-02,  1.7571e-03,  1.2593e-01],\n",
              "                        [ 1.7871e-01, -6.3029e-03,  6.1552e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.4360e-01,  1.0174e-01, -7.1904e-02],\n",
              "                        [-6.6108e-02,  6.1604e-03, -8.6552e-02],\n",
              "                        [-2.5588e-02,  4.1259e-02, -1.1755e-01]],\n",
              "              \n",
              "                       [[ 6.0778e-02,  5.1438e-02, -6.8248e-02],\n",
              "                        [ 1.4288e-02,  9.7781e-02, -1.0609e-01],\n",
              "                        [-2.0555e-02, -1.8163e-01,  1.6735e-01]],\n",
              "              \n",
              "                       [[ 1.1862e-01,  1.7950e-01,  1.7732e-01],\n",
              "                        [ 1.1967e-01,  8.7708e-02,  4.8925e-02],\n",
              "                        [-6.5647e-03, -5.4232e-02,  6.6060e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.6488e-02, -2.2504e-02,  1.7066e-01],\n",
              "                        [ 5.8568e-02, -1.5761e-01, -7.6865e-02],\n",
              "                        [ 1.8818e-01,  7.0095e-02, -5.6873e-03]],\n",
              "              \n",
              "                       [[ 1.7945e-01, -1.7028e-01,  3.8284e-02],\n",
              "                        [ 8.6448e-02, -4.0714e-02,  9.1065e-02],\n",
              "                        [-1.5479e-01,  4.5240e-02, -1.3701e-01]],\n",
              "              \n",
              "                       [[ 9.4844e-02,  3.9106e-02,  1.4835e-01],\n",
              "                        [ 1.8790e-01,  1.0057e-01,  6.0344e-02],\n",
              "                        [ 1.9011e-01,  1.8006e-01,  1.6030e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.8501e-01,  1.1185e-01, -1.6411e-01],\n",
              "                        [ 8.1135e-02,  1.0966e-01,  1.7021e-01],\n",
              "                        [-1.3241e-01,  6.1075e-02,  6.8509e-02]],\n",
              "              \n",
              "                       [[-7.8755e-02, -8.5064e-02,  1.6783e-01],\n",
              "                        [-1.7267e-02,  4.0571e-02,  1.4983e-01],\n",
              "                        [ 9.8512e-03, -2.5308e-02,  3.7234e-02]],\n",
              "              \n",
              "                       [[ 1.0836e-01,  1.1016e-01,  2.7212e-02],\n",
              "                        [ 4.2081e-02,  6.9351e-02, -1.6094e-01],\n",
              "                        [-3.0126e-02,  1.5205e-01, -3.2578e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.5037e-01, -1.8763e-01, -1.3715e-01],\n",
              "                        [ 1.7187e-01, -8.4553e-02, -1.6600e-01],\n",
              "                        [-1.5278e-01,  2.7566e-02, -1.2547e-01]],\n",
              "              \n",
              "                       [[-1.3032e-01,  7.6038e-02,  1.7810e-01],\n",
              "                        [ 1.4721e-01, -1.1250e-01, -3.5119e-02],\n",
              "                        [ 1.4540e-01, -9.6666e-03,  8.8305e-02]],\n",
              "              \n",
              "                       [[ 1.3281e-01,  1.5297e-01, -1.5923e-01],\n",
              "                        [-1.3060e-01, -3.2384e-02,  1.2597e-01],\n",
              "                        [ 5.4699e-03, -1.2721e-01,  1.2002e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.6039e-01, -4.7174e-02,  1.1951e-01],\n",
              "                        [-1.3862e-01, -2.4744e-02, -1.0049e-01],\n",
              "                        [ 6.8809e-03,  3.6125e-02, -3.8012e-03]],\n",
              "              \n",
              "                       [[-3.0296e-02, -7.0663e-02,  9.0533e-02],\n",
              "                        [ 1.4312e-01,  3.8820e-02,  1.5689e-01],\n",
              "                        [-1.0484e-01,  1.5789e-01, -2.4436e-02]],\n",
              "              \n",
              "                       [[ 1.7999e-01, -7.9829e-03, -1.2211e-01],\n",
              "                        [-4.5951e-03, -1.1936e-01,  1.7396e-01],\n",
              "                        [-8.6122e-02,  1.6155e-01, -1.3512e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.4841e-01,  1.6795e-01, -1.7454e-01],\n",
              "                        [ 6.0854e-02,  1.8915e-01,  1.0069e-02],\n",
              "                        [-1.4195e-02, -1.0787e-01,  1.4728e-01]],\n",
              "              \n",
              "                       [[-2.0077e-02, -3.1616e-02, -1.4839e-01],\n",
              "                        [ 1.3496e-01, -1.0583e-01,  1.1588e-01],\n",
              "                        [-9.6008e-02, -4.7732e-02, -1.2178e-01]],\n",
              "              \n",
              "                       [[-1.6387e-01,  1.3471e-01, -4.6143e-02],\n",
              "                        [-3.5702e-02,  1.7042e-01, -2.9337e-02],\n",
              "                        [-1.4438e-01,  1.1691e-01,  3.9909e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.6722e-02, -1.0714e-01,  1.8452e-01],\n",
              "                        [-4.5815e-02, -3.8531e-02,  2.0713e-02],\n",
              "                        [-1.7328e-01,  1.4750e-01,  1.2694e-01]],\n",
              "              \n",
              "                       [[ 1.5168e-01,  1.6327e-01, -1.5577e-01],\n",
              "                        [-1.8085e-01,  1.8771e-01,  8.2178e-02],\n",
              "                        [-1.9309e-03,  1.5067e-02, -4.5764e-02]],\n",
              "              \n",
              "                       [[-1.1422e-01,  9.9598e-02, -8.4942e-02],\n",
              "                        [ 5.1699e-02,  1.2980e-01,  1.7053e-01],\n",
              "                        [-2.3994e-02,  4.2359e-02, -1.7099e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.4505e-01,  9.2694e-02,  1.1924e-01],\n",
              "                        [-1.0857e-01,  1.0423e-01, -1.6079e-01],\n",
              "                        [ 5.4104e-02,  8.8177e-02,  9.7538e-02]],\n",
              "              \n",
              "                       [[-7.2593e-02,  1.2099e-01, -1.0758e-01],\n",
              "                        [-1.9112e-01,  1.1038e-02, -1.5671e-01],\n",
              "                        [ 9.0844e-02, -8.0270e-02,  7.8240e-02]],\n",
              "              \n",
              "                       [[ 1.4004e-01,  3.1056e-02,  3.0583e-02],\n",
              "                        [ 1.2093e-01, -7.8591e-02,  1.7946e-01],\n",
              "                        [ 1.1989e-01, -7.6505e-02, -9.4305e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.1997e-03,  1.7196e-01,  1.8355e-01],\n",
              "                        [-3.9705e-02,  6.3886e-02,  1.8311e-01],\n",
              "                        [ 9.3717e-02,  9.9770e-02, -4.0133e-02]],\n",
              "              \n",
              "                       [[ 9.5210e-02, -8.3570e-02, -7.6518e-02],\n",
              "                        [ 2.2864e-02, -8.9760e-02,  9.2133e-02],\n",
              "                        [ 1.5512e-01,  1.2613e-01,  8.4086e-02]],\n",
              "              \n",
              "                       [[ 2.5686e-02,  1.5898e-01, -2.0872e-02],\n",
              "                        [ 5.9616e-02,  1.0317e-01, -1.0583e-01],\n",
              "                        [-1.0529e-01,  3.8174e-02,  7.6546e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.8177e-01,  8.1980e-02,  1.6831e-01],\n",
              "                        [ 1.1722e-01, -1.7707e-02, -1.0544e-01],\n",
              "                        [ 9.9799e-02,  1.2429e-01,  1.8076e-01]],\n",
              "              \n",
              "                       [[-1.4227e-01, -1.3649e-01,  1.5897e-01],\n",
              "                        [ 1.1499e-01, -1.1394e-01,  1.4254e-01],\n",
              "                        [ 1.5280e-01, -1.7233e-01, -6.7690e-02]],\n",
              "              \n",
              "                       [[-6.5770e-02, -3.1154e-02,  1.1270e-01],\n",
              "                        [ 7.6346e-02,  1.3017e-01,  1.5448e-01],\n",
              "                        [ 1.7924e-01, -3.5089e-02, -1.5566e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-9.8317e-02,  2.8748e-02, -1.0125e-01],\n",
              "                        [ 1.5146e-01, -1.5531e-01,  1.4843e-01],\n",
              "                        [-6.0333e-02, -1.5030e-01, -1.7918e-01]],\n",
              "              \n",
              "                       [[-1.3101e-03, -1.1484e-01,  1.4562e-01],\n",
              "                        [-4.2573e-02, -1.3323e-01,  2.6423e-02],\n",
              "                        [-1.8153e-01,  1.7217e-01, -7.3040e-02]],\n",
              "              \n",
              "                       [[-1.4221e-01, -7.8213e-02, -6.6205e-02],\n",
              "                        [ 1.2588e-01, -1.0816e-01, -1.2818e-01],\n",
              "                        [-1.2941e-01, -5.0902e-02,  5.8357e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.0396e-02,  1.5550e-01,  1.7114e-01],\n",
              "                        [ 2.1828e-02,  2.7588e-02,  1.4013e-01],\n",
              "                        [-8.1125e-02,  1.2075e-01, -1.4040e-01]],\n",
              "              \n",
              "                       [[ 5.2367e-02, -1.1003e-01, -1.1535e-01],\n",
              "                        [ 5.5818e-02, -1.5740e-01,  4.0353e-02],\n",
              "                        [-1.0803e-01,  4.6314e-02, -3.3696e-02]],\n",
              "              \n",
              "                       [[ 5.4422e-02,  4.1407e-02,  4.5754e-02],\n",
              "                        [-1.6085e-01,  5.3892e-02, -5.4476e-02],\n",
              "                        [-7.1653e-02,  1.5873e-01,  1.8498e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.4748e-01,  2.5821e-02,  1.8958e-01],\n",
              "                        [-6.1957e-02,  6.9993e-02,  1.1118e-02],\n",
              "                        [ 1.8646e-01,  1.8691e-01, -1.2524e-01]],\n",
              "              \n",
              "                       [[-1.5978e-01,  4.6713e-02, -1.6481e-01],\n",
              "                        [ 1.8247e-01, -1.0111e-01,  1.0463e-01],\n",
              "                        [-1.4630e-01,  1.3698e-01,  1.7403e-01]],\n",
              "              \n",
              "                       [[-6.1143e-02,  8.3832e-03,  6.2206e-03],\n",
              "                        [ 1.0253e-02, -7.3032e-02, -1.8727e-01],\n",
              "                        [-1.4623e-01, -1.7551e-01, -1.0195e-01]]]])),\n",
              "             ('conv.bias',\n",
              "              tensor([ 0.1331,  0.1162, -0.0867,  0.1187,  0.0895,  0.0830,  0.0196, -0.1310,\n",
              "                      -0.1855, -0.0911,  0.1009,  0.0460,  0.1708,  0.1881, -0.0506,  0.0612])),\n",
              "             ('linear.weight',\n",
              "              tensor([[ 0.0461, -0.1579, -0.1704, -0.0403, -0.0533,  0.0436, -0.1208,  0.2476,\n",
              "                       -0.2151, -0.0240,  0.1123, -0.0782, -0.0161,  0.0520,  0.0373,  0.0560],\n",
              "                      [ 0.1809, -0.1185, -0.0383, -0.0441, -0.1727, -0.2340, -0.1332, -0.0278,\n",
              "                       -0.2375, -0.0706,  0.0423,  0.2131, -0.1277,  0.0739,  0.2209, -0.1023],\n",
              "                      [ 0.2197, -0.1776,  0.0334, -0.0526, -0.1792, -0.0594, -0.2417,  0.1647,\n",
              "                       -0.0972,  0.1548,  0.2406,  0.2206,  0.0912,  0.2038, -0.0108, -0.2298]])),\n",
              "             ('linear.bias', tensor([-0.1724,  0.2483, -0.2493]))])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "\n",
        "print('listing params : ')\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCgjKvSe7IgL",
        "outputId": "b0afd650-a650-4974-a176-6457c11f3f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 502\n",
            "listing params : \n",
            "default_param torch.Size([3])\n",
            "conv.weight torch.Size([16, 3, 3, 3])\n",
            "conv.bias torch.Size([16])\n",
            "linear.weight torch.Size([3, 16])\n",
            "linear.bias torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(y, params=dict(model.named_parameters()))"
      ],
      "metadata": {
        "id": "h_icxR4y7PNX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "878f1cbd-e0a9-47c6-a799-e993bb849053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"368pt\" height=\"633pt\"\n viewBox=\"0.00 0.00 368.00 633.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 629)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-629 364,-629 364,4 -4,4\"/>\n<!-- 133303502369712 -->\n<g id=\"node1\" class=\"node\">\n<title>133303502369712</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"258,-31 199,-31 199,0 258,0 258,-31\"/>\n<text text-anchor=\"middle\" x=\"228.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 3)</text>\n</g>\n<!-- 133303501923968 -->\n<g id=\"node2\" class=\"node\">\n<title>133303501923968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"273,-86 184,-86 184,-67 273,-67 273,-86\"/>\n<text text-anchor=\"middle\" x=\"228.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133303501923968&#45;&gt;133303502369712 -->\n<g id=\"edge19\" class=\"edge\">\n<title>133303501923968&#45;&gt;133303502369712</title>\n<path fill=\"none\" stroke=\"black\" d=\"M228.5,-66.79C228.5,-60.07 228.5,-50.4 228.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"232,-41.19 228.5,-31.19 225,-41.19 232,-41.19\"/>\n</g>\n<!-- 133303501914320 -->\n<g id=\"node3\" class=\"node\">\n<title>133303501914320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-141 128,-141 128,-122 217,-122 217,-141\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133303501914320&#45;&gt;133303501923968 -->\n<g id=\"edge1\" class=\"edge\">\n<title>133303501914320&#45;&gt;133303501923968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M181.5,-121.98C189.69,-114.23 202.01,-102.58 211.97,-93.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.48,-95.59 219.34,-86.17 209.67,-90.5 214.48,-95.59\"/>\n</g>\n<!-- 133303501915232 -->\n<g id=\"node4\" class=\"node\">\n<title>133303501915232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-201.5 128,-201.5 128,-182.5 217,-182.5 217,-201.5\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133303501915232&#45;&gt;133303501914320 -->\n<g id=\"edge2\" class=\"edge\">\n<title>133303501915232&#45;&gt;133303501914320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.5,-182.37C172.5,-174.25 172.5,-161.81 172.5,-151.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176,-151.17 172.5,-141.17 169,-151.17 176,-151.17\"/>\n</g>\n<!-- 133303501918592 -->\n<g id=\"node5\" class=\"node\">\n<title>133303501918592</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-262 128,-262 128,-243 217,-243 217,-262\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133303501918592&#45;&gt;133303501915232 -->\n<g id=\"edge3\" class=\"edge\">\n<title>133303501918592&#45;&gt;133303501915232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.5,-242.87C172.5,-234.75 172.5,-222.31 172.5,-211.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176,-211.67 172.5,-201.67 169,-211.67 176,-211.67\"/>\n</g>\n<!-- 133303501915856 -->\n<g id=\"node6\" class=\"node\">\n<title>133303501915856</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-317 128,-317 128,-298 217,-298 217,-317\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133303501915856&#45;&gt;133303501918592 -->\n<g id=\"edge4\" class=\"edge\">\n<title>133303501915856&#45;&gt;133303501918592</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.5,-297.75C172.5,-290.8 172.5,-280.85 172.5,-272.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176,-272.09 172.5,-262.09 169,-272.09 176,-272.09\"/>\n</g>\n<!-- 133303501922480 -->\n<g id=\"node7\" class=\"node\">\n<title>133303501922480</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"223,-372 122,-372 122,-353 223,-353 223,-372\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 133303501922480&#45;&gt;133303501915856 -->\n<g id=\"edge5\" class=\"edge\">\n<title>133303501922480&#45;&gt;133303501915856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.5,-352.75C172.5,-345.8 172.5,-335.85 172.5,-327.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176,-327.09 172.5,-317.09 169,-327.09 176,-327.09\"/>\n</g>\n<!-- 133303501916048 -->\n<g id=\"node8\" class=\"node\">\n<title>133303501916048</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-427 0,-427 0,-408 101,-408 101,-427\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-415\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133303501916048&#45;&gt;133303501922480 -->\n<g id=\"edge6\" class=\"edge\">\n<title>133303501916048&#45;&gt;133303501922480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M70.1,-407.98C89.82,-399.42 120.45,-386.11 143.08,-376.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"144.76,-379.37 152.54,-372.17 141.98,-372.94 144.76,-379.37\"/>\n</g>\n<!-- 133303502368560 -->\n<g id=\"node9\" class=\"node\">\n<title>133303502368560</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"86,-493 3,-493 3,-463 86,-463 86,-493\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\">linear.bias</text>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-470\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133303502368560&#45;&gt;133303501916048 -->\n<g id=\"edge7\" class=\"edge\">\n<title>133303502368560&#45;&gt;133303501916048</title>\n<path fill=\"none\" stroke=\"black\" d=\"M45.95,-462.84C46.73,-455.21 47.71,-445.7 48.56,-437.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"52.06,-437.57 49.6,-427.27 45.1,-436.86 52.06,-437.57\"/>\n</g>\n<!-- 133303501922000 -->\n<g id=\"node10\" class=\"node\">\n<title>133303501922000</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-427 125,-427 125,-408 220,-408 220,-427\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-415\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward1</text>\n</g>\n<!-- 133303501922000&#45;&gt;133303501922480 -->\n<g id=\"edge8\" class=\"edge\">\n<title>133303501922000&#45;&gt;133303501922480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.5,-407.75C172.5,-400.8 172.5,-390.85 172.5,-382.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176,-382.09 172.5,-372.09 169,-382.09 176,-382.09\"/>\n</g>\n<!-- 133303501928096 -->\n<g id=\"node11\" class=\"node\">\n<title>133303501928096</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"241,-487.5 104,-487.5 104,-468.5 241,-468.5 241,-487.5\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-475.5\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 133303501928096&#45;&gt;133303501922000 -->\n<g id=\"edge9\" class=\"edge\">\n<title>133303501928096&#45;&gt;133303501922000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.5,-468.37C172.5,-460.25 172.5,-447.81 172.5,-437.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176,-437.17 172.5,-427.17 169,-437.17 176,-437.17\"/>\n</g>\n<!-- 133303501919216 -->\n<g id=\"node12\" class=\"node\">\n<title>133303501919216</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114,-553.5 13,-553.5 13,-534.5 114,-534.5 114,-553.5\"/>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-541.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133303501919216&#45;&gt;133303501928096 -->\n<g id=\"edge10\" class=\"edge\">\n<title>133303501919216&#45;&gt;133303501928096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M78.2,-534.37C96.32,-523.73 127.35,-505.51 148.84,-492.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.83,-495.78 157.68,-487.7 147.29,-489.74 150.83,-495.78\"/>\n</g>\n<!-- 133303502362992 -->\n<g id=\"node13\" class=\"node\">\n<title>133303502362992</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"114,-625 13,-625 13,-595 114,-595 114,-625\"/>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-613\" font-family=\"monospace\" font-size=\"10.00\">conv.weight</text>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-602\" font-family=\"monospace\" font-size=\"10.00\"> (16, 3, 3, 3)</text>\n</g>\n<!-- 133303502362992&#45;&gt;133303501919216 -->\n<g id=\"edge11\" class=\"edge\">\n<title>133303502362992&#45;&gt;133303501919216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.5,-594.8C63.5,-585.7 63.5,-573.79 63.5,-563.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"67,-563.84 63.5,-553.84 60,-563.84 67,-563.84\"/>\n</g>\n<!-- 133303501919072 -->\n<g id=\"node14\" class=\"node\">\n<title>133303501919072</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"233,-553.5 132,-553.5 132,-534.5 233,-534.5 233,-553.5\"/>\n<text text-anchor=\"middle\" x=\"182.5\" y=\"-541.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133303501919072&#45;&gt;133303501928096 -->\n<g id=\"edge12\" class=\"edge\">\n<title>133303501919072&#45;&gt;133303501928096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M181.15,-534.37C179.7,-525.07 177.34,-509.98 175.45,-497.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"178.89,-497.25 173.89,-487.91 171.98,-498.33 178.89,-497.25\"/>\n</g>\n<!-- 133303502368656 -->\n<g id=\"node15\" class=\"node\">\n<title>133303502368656</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"218,-625 147,-625 147,-595 218,-595 218,-625\"/>\n<text text-anchor=\"middle\" x=\"182.5\" y=\"-613\" font-family=\"monospace\" font-size=\"10.00\">conv.bias</text>\n<text text-anchor=\"middle\" x=\"182.5\" y=\"-602\" font-family=\"monospace\" font-size=\"10.00\"> (16)</text>\n</g>\n<!-- 133303502368656&#45;&gt;133303501919072 -->\n<g id=\"edge13\" class=\"edge\">\n<title>133303502368656&#45;&gt;133303501919072</title>\n<path fill=\"none\" stroke=\"black\" d=\"M182.5,-594.8C182.5,-585.7 182.5,-573.79 182.5,-563.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186,-563.84 182.5,-553.84 179,-563.84 186,-563.84\"/>\n</g>\n<!-- 133303501922048 -->\n<g id=\"node16\" class=\"node\">\n<title>133303501922048</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"331,-427 254,-427 254,-408 331,-408 331,-427\"/>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-415\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 133303501922048&#45;&gt;133303501922480 -->\n<g id=\"edge14\" class=\"edge\">\n<title>133303501922048&#45;&gt;133303501922480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M273.22,-407.98C253.83,-399.42 223.69,-386.11 201.43,-376.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"202.69,-373.01 192.13,-372.17 199.86,-379.41 202.69,-373.01\"/>\n</g>\n<!-- 133303501917104 -->\n<g id=\"node17\" class=\"node\">\n<title>133303501917104</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"360,-487.5 259,-487.5 259,-468.5 360,-468.5 360,-487.5\"/>\n<text text-anchor=\"middle\" x=\"309.5\" y=\"-475.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133303501917104&#45;&gt;133303501922048 -->\n<g id=\"edge15\" class=\"edge\">\n<title>133303501917104&#45;&gt;133303501922048</title>\n<path fill=\"none\" stroke=\"black\" d=\"M306.99,-468.37C304.61,-460.16 300.94,-447.54 297.89,-437.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"301.17,-435.79 295.02,-427.17 294.45,-437.75 301.17,-435.79\"/>\n</g>\n<!-- 133303502364624 -->\n<g id=\"node18\" class=\"node\">\n<title>133303502364624</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"357,-559 262,-559 262,-529 357,-529 357,-559\"/>\n<text text-anchor=\"middle\" x=\"309.5\" y=\"-547\" font-family=\"monospace\" font-size=\"10.00\">linear.weight</text>\n<text text-anchor=\"middle\" x=\"309.5\" y=\"-536\" font-family=\"monospace\" font-size=\"10.00\"> (3, 16)</text>\n</g>\n<!-- 133303502364624&#45;&gt;133303501917104 -->\n<g id=\"edge16\" class=\"edge\">\n<title>133303502364624&#45;&gt;133303501917104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M309.5,-528.8C309.5,-519.7 309.5,-507.79 309.5,-497.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"313,-497.84 309.5,-487.84 306,-497.84 313,-497.84\"/>\n</g>\n<!-- 133303501927808 -->\n<g id=\"node19\" class=\"node\">\n<title>133303501927808</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"336,-141 235,-141 235,-122 336,-122 336,-141\"/>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133303501927808&#45;&gt;133303501923968 -->\n<g id=\"edge17\" class=\"edge\">\n<title>133303501927808&#45;&gt;133303501923968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.34,-121.98C268,-114.23 255.47,-102.58 245.32,-93.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"247.53,-90.42 237.82,-86.17 242.76,-95.54 247.53,-90.42\"/>\n</g>\n<!-- 133303502369232 -->\n<g id=\"node20\" class=\"node\">\n<title>133303502369232</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"333,-207 238,-207 238,-177 333,-177 333,-207\"/>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">default_param</text>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133303502369232&#45;&gt;133303501927808 -->\n<g id=\"edge18\" class=\"edge\">\n<title>133303502369232&#45;&gt;133303501927808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M285.5,-176.84C285.5,-169.21 285.5,-159.7 285.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"289,-151.27 285.5,-141.27 282,-151.27 289,-151.27\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x793d23ee67d0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular tensors are only added to PyTorch's computation graph if they either:\n",
        "\n",
        "*   Are registered as `nn.Parameter`\n",
        "*   Have `requires_grad=True`\n",
        "*   Result from operations involving tensors that require gradients\n",
        "\n",
        "Furthermore, there's a key difference between:\n",
        "\n",
        "* Being in computation graph (`requires_grad=True`): Gets gradients during backprop\n",
        "* Being in `model.parameters()`: Gets both gradients **AND** optimizer updates\n",
        "\n",
        "This is why we register trainable weights as `nn.Parameter` rather than just using `requires_grad=True` on regular tensors.\n",
        "\n",
        "All other tensors (instance attributes, class attributes, global variables, buffers) are not tracked for automatic differentiation."
      ],
      "metadata": {
        "id": "AbrIco3kkZlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch contiguous experiments"
      ],
      "metadata": {
        "id": "Cn3-HjacwEeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding **stride**"
      ],
      "metadata": {
        "id": "RGGxKKY5GLC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
        "print(f\"Original tensor x:\\n{x}\\n\")\n",
        "print('stride : ', x.stride())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEJ8BmE6wWK2",
        "outputId": "72f04135-2c06-4b55-815c-f56b0bdcb357"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor x:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "stride :  (3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stride values (3, 1) for this tensor of shape [2, 3] tell us exactly how the elements are laid out in memory:\n",
        "\n",
        "The first value 3 is the stride for the first dimension (rows).\n",
        "\n",
        "This means when you move down one row, you need to jump 3 elements in the linear memory.\n",
        "\n",
        "The second value 1 is the stride for the second dimension (columns). This means when you move right one column, you need to jump 1 element in the linear memory.\n",
        "\n",
        "Let's visualize how this maps a 23 tensor to a linear memory array:\n",
        "If we have a tensor that looks like:\n",
        "```\n",
        "[  \n",
        "  [a, b, c],\n",
        "  [d, e, f]\n",
        "]\n",
        "```\n",
        "\n",
        "With strides (3, 1), the elements are stored in memory as:\n",
        "```\n",
        "[a, b, c, d, e, f]\n",
        "```\n"
      ],
      "metadata": {
        "id": "IUb_ecwD-QUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.transpose(0, 1)\n",
        "print(\"\\n===== AFTER TRANSPOSE =====\")\n",
        "print(f\"Transposed tensor y:\\n{y}\")\n",
        "print(f\"New shape: {y.shape}\")\n",
        "print(f\"New strides: {y.stride()}\")\n",
        "print(f\"New is contiguous: {y.is_contiguous()}\")\n",
        "print(f\"Still using same storage?: {x.storage().data_ptr() == y.storage().data_ptr()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXEvGsWP6aY9",
        "outputId": "68776845-335a-4725-eb89-78a05bb851c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== AFTER TRANSPOSE =====\n",
            "Transposed tensor y:\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n",
            "New shape: torch.Size([3, 2])\n",
            "New strides: (1, 3)\n",
            "New is contiguous: False\n",
            "Still using same storage?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transposed tensor logically looks like:\n",
        "```\n",
        "[\n",
        "  [a, d],\n",
        "  [b, e],\n",
        "  [c, f]\n",
        "]\n",
        "```\n",
        "\n",
        "But the underlying storage is still the same linear array:\n",
        "```\n",
        "[a, b, c, d, e, f]\n",
        "```"
      ],
      "metadata": {
        "id": "tN6BeF2d-9fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_same_tensor(t1, t2):\n",
        "    \"\"\"Check if two tensors share the same underlying storage.\"\"\"\n",
        "    return t1.storage().data_ptr() == t2.storage().data_ptr()\n",
        "\n",
        "def print_tensor_info(name, tensor):\n",
        "    \"\"\"Print information about a tensor's memory layout.\"\"\"\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Shape: {tensor.shape}\")\n",
        "    print(f\"  Strides: {tensor.stride()}\")\n",
        "    print(f\"  Storage offset: {tensor.storage_offset()}\")\n",
        "    print(f\"  Is contiguous: {tensor.is_contiguous()}\")\n",
        "    print(f\"  Memory address: {tensor.data_ptr()}\")"
      ],
      "metadata": {
        "id": "l07u0JsP6miL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example 1, Tensor slicing**\n",
        "\n"
      ],
      "metadata": {
        "id": "zyTfgs15EDKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original = torch.arange(12).reshape(3, 4)\n",
        "print_tensor_info(\"Original tensor\", original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upmntvBkDrqS",
        "outputId": "48415a36-c927-46a1-c2b3-a01f6e26fea9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original tensor:\n",
            "  Shape: torch.Size([3, 4])\n",
            "  Strides: (4, 1)\n",
            "  Storage offset: 0\n",
            "  Is contiguous: True\n",
            "  Memory address: 129634816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWUvSy2MMWq3",
        "outputId": "681bd414-8abe-4414-bdc2-717fb72bca1b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sliced = original[:2, :2]\n",
        "print_tensor_info(\"Sliced tensor\", sliced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAgcYVv2Dtnf",
        "outputId": "b6ca0446-632c-4c31-9520-07826deb0e01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sliced tensor:\n",
            "  Shape: torch.Size([2, 2])\n",
            "  Strides: (4, 1)\n",
            "  Storage offset: 0\n",
            "  Is contiguous: False\n",
            "  Memory address: 129634816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sliced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO0836iKFhZx",
        "outputId": "afe44a04-3e03-4bb7-dac3-e511c2f67d15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sliced_contiguous = sliced.contiguous()\n",
        "print_tensor_info(\"Sliced after .contiguous()\", sliced_contiguous)\n",
        "print(f\"Sliced and its .contiguous() share storage: {is_same_tensor(sliced, sliced_contiguous)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxtT3a3oDxUR",
        "outputId": "36200b03-0cec-48b3-d872-dcc03488050f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sliced after .contiguous():\n",
            "  Shape: torch.Size([2, 2])\n",
            "  Strides: (2, 1)\n",
            "  Storage offset: 0\n",
            "  Is contiguous: True\n",
            "  Memory address: 130007168\n",
            "Sliced and its .contiguous() share storage: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6gdA0WjXENhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example 2, Tensor tranpose**\n",
        "\n"
      ],
      "metadata": {
        "id": "J_4izoZRESIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transposed = original.transpose(0, 1)\n",
        "print_tensor_info(\"Transposed tensor (non-contiguous)\", transposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UGHBx_tD69u",
        "outputId": "8e40b288-d062-49a1-c080-6bc5c264c41b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transposed tensor (non-contiguous):\n",
            "  Shape: torch.Size([4, 3])\n",
            "  Strides: (1, 4)\n",
            "  Storage offset: 0\n",
            "  Is contiguous: False\n",
            "  Memory address: 129634816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transposed_contiguous = transposed.contiguous()\n",
        "print_tensor_info(\"Transposed after .contiguous()\", transposed_contiguous)\n",
        "print(f\"Transposed and its .contiguous() share storage: {is_same_tensor(transposed, transposed_contiguous)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EWjUwudEZgq",
        "outputId": "4c84ce90-46f2-412c-d897-fd43bf31e1e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transposed after .contiguous():\n",
            "  Shape: torch.Size([4, 3])\n",
            "  Strides: (3, 1)\n",
            "  Storage offset: 0\n",
            "  Is contiguous: True\n",
            "  Memory address: 130642624\n",
            "Transposed and its .contiguous() share storage: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMemory layout visualization:\")\n",
        "print(\"Original tensor memory layout:\")\n",
        "print(original.storage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg7ww5vDEc5C",
        "outputId": "20a541cf-502c-489e-a361-28105d1fb306"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Memory layout visualization:\n",
            "Original tensor memory layout:\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            " 9\n",
            " 10\n",
            " 11\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTransposed tensor (logical view):\")\n",
        "print(transposed)\n",
        "print(\"\\nTransposed tensor storage:\")\n",
        "print(transposed.storage())\n",
        "print(transposed.is_contiguous())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8DikLiaEkyx",
        "outputId": "c0853e2c-c189-4526-d879-ebb9009176e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transposed tensor (logical view):\n",
            "tensor([[ 0,  4,  8],\n",
            "        [ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11]])\n",
            "\n",
            "Transposed tensor storage:\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            " 9\n",
            " 10\n",
            " 11\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 12]\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTransposed and made contiguous (actual memory rearranged):\")\n",
        "print(transposed_contiguous.storage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpFf40ZeFBLs",
        "outputId": "7c2f8769-a77d-40f8-ddf9-438217d919c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transposed and made contiguous (actual memory rearranged):\n",
            " 0\n",
            " 4\n",
            " 8\n",
            " 1\n",
            " 5\n",
            " 9\n",
            " 2\n",
            " 6\n",
            " 10\n",
            " 3\n",
            " 7\n",
            " 11\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMTTJlc8FDzm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}